import os
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
from models.schemas import AnalysisResult, RepositoryAnalysis, TechSpec, CorrelationAnalysis


class MarkdownGenerator:
    """ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, output_dir: str = "output/markdown"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
    
    def generate_analysis_report(self, analysis_result: AnalysisResult) -> str:
        """ë¶„ì„ ê²°ê³¼ ì „ì²´ë¥¼ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ë¡œ ìƒì„±"""
        md_content = []
        
        # í—¤ë” ìƒì„±
        md_content.append(self._generate_header(analysis_result))
        
        # ë¶„ì„ ê°œìš”
        md_content.append(self._generate_overview(analysis_result))
        
        # ë ˆí¬ì§€í† ë¦¬ë³„ ìƒì„¸ ë¶„ì„
        for i, repo in enumerate(analysis_result.repositories, 1):
            md_content.append(self._generate_repository_section(repo, i))
        
        # ì—°ê´€ë„ ë¶„ì„ (ìˆëŠ” ê²½ìš°)
        if analysis_result.correlation_analysis:
            md_content.append(self._generate_correlation_section(analysis_result.correlation_analysis))
        
        # ìš”ì•½ ë° ê¶Œì¥ì‚¬í•­
        md_content.append(self._generate_summary_section(analysis_result))
        
        return "\n\n".join(md_content)
    
    def _generate_header(self, analysis_result: AnalysisResult) -> str:
        """ë§ˆí¬ë‹¤ìš´ í—¤ë” ìƒì„±"""
        created_date = analysis_result.created_at.strftime("%Y-%m-%d %H:%M:%S") if analysis_result.created_at else "Unknown"
        completed_date = analysis_result.completed_at.strftime("%Y-%m-%d %H:%M:%S") if analysis_result.completed_at else "In Progress"
        
        return f"""# ğŸ“Š ì½”ë“œ ë¶„ì„ ë¦¬í¬íŠ¸

**ë¶„ì„ ID**: `{analysis_result.analysis_id}`  
**ìƒì„± ì¼ì‹œ**: {created_date}  
**ì™„ë£Œ ì¼ì‹œ**: {completed_date}  
**ìƒíƒœ**: {analysis_result.status.value}  
**ë¶„ì„ ëŒ€ìƒ**: {len(analysis_result.repositories)}ê°œ ë ˆí¬ì§€í† ë¦¬

---"""
    
    def _generate_overview(self, analysis_result: AnalysisResult) -> str:
        """ë¶„ì„ ê°œìš” ì„¹ì…˜ ìƒì„±"""
        total_files = sum(len(repo.files) for repo in analysis_result.repositories)
        total_lines = sum(repo.code_metrics.lines_of_code for repo in analysis_result.repositories)
        
        languages = set()
        frameworks = set()
        
        for repo in analysis_result.repositories:
            for tech_spec in repo.tech_specs:
                if tech_spec.language:
                    languages.add(tech_spec.language)
                if tech_spec.framework:
                    frameworks.add(tech_spec.framework)
        
        overview = f"""## ğŸ“‹ ë¶„ì„ ê°œìš”

### ğŸ“Š í†µê³„ ì •ë³´
- **ì´ íŒŒì¼ ìˆ˜**: {total_files:,}ê°œ
- **ì´ ì½”ë“œ ë¼ì¸ ìˆ˜**: {total_lines:,}ì¤„
- **ì‚¬ìš© ì–¸ì–´**: {', '.join(sorted(languages)) if languages else 'N/A'}
- **ì£¼ìš” í”„ë ˆì„ì›Œí¬**: {', '.join(sorted(frameworks)) if frameworks else 'N/A'}

### ğŸ¯ ë¶„ì„ ë²”ìœ„
- **AST ë¶„ì„**: {'âœ… í¬í•¨' if any(repo.ast_analysis for repo in analysis_result.repositories) else 'âŒ ì œì™¸'}
- **ê¸°ìˆ  ìŠ¤í™ ë¶„ì„**: {'âœ… í¬í•¨' if any(repo.tech_specs for repo in analysis_result.repositories) else 'âŒ ì œì™¸'}
- **ì—°ê´€ë„ ë¶„ì„**: {'âœ… í¬í•¨' if analysis_result.correlation_analysis else 'âŒ ì œì™¸'}"""
        
        return overview
    
    def _generate_repository_section(self, repo: RepositoryAnalysis, index: int) -> str:
        """ë ˆí¬ì§€í† ë¦¬ë³„ ìƒì„¸ ë¶„ì„ ì„¹ì…˜ ìƒì„±"""
        section = f"""## {index}. ğŸ“ {repo.repository.name}

**URL**: [{repo.repository.url}]({repo.repository.url})  
**ë¸Œëœì¹˜**: `{repo.repository.branch}`  
**í´ë¡  ê²½ë¡œ**: `{repo.clone_path}`

### ğŸ“Š ì½”ë“œ ë©”íŠ¸ë¦­ìŠ¤
- **íŒŒì¼ ìˆ˜**: {len(repo.files)}ê°œ
- **ì½”ë“œ ë¼ì¸ ìˆ˜**: {repo.code_metrics.lines_of_code:,}ì¤„
- **ìˆœí™˜ ë³µì¡ë„**: {repo.code_metrics.cyclomatic_complexity:.2f}
- **ìœ ì§€ë³´ìˆ˜ì„± ì§€ìˆ˜**: {repo.code_metrics.maintainability_index:.2f}"""
        
        # ê¸°ìˆ  ìŠ¤í™ ì •ë³´
        if repo.tech_specs:
            section += "\n\n### ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ"
            for tech_spec in repo.tech_specs:
                section += f"""
- **ì–¸ì–´**: {tech_spec.language}
- **í”„ë ˆì„ì›Œí¬**: {tech_spec.framework}
- **ë²„ì „**: {tech_spec.version}
- **íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €**: {tech_spec.package_manager}
- **ì£¼ìš” ì˜ì¡´ì„±**: {', '.join(tech_spec.dependencies[:10]) if tech_spec.dependencies else 'N/A'}"""
        
        # AST ë¶„ì„ ì •ë³´
        if repo.ast_analysis:
            section += f"\n\n### ğŸŒ³ AST ë¶„ì„ ê²°ê³¼"
            total_nodes = sum(len(nodes) for nodes in repo.ast_analysis.values())
            section += f"\n- **ì´ ë…¸ë“œ ìˆ˜**: {total_nodes}ê°œ"
            
            # íŒŒì¼ë³„ AST í†µê³„
            for file_path, nodes in repo.ast_analysis.items():
                functions = [node for node in nodes if node.type == "function"]
                classes = [node for node in nodes if node.type == "class"]
                
                if functions or classes:
                    section += f"\n- **{file_path}**: í•¨ìˆ˜ {len(functions)}ê°œ, í´ë˜ìŠ¤ {len(classes)}ê°œ"
        
        # íŒŒì¼ ëª©ë¡ (ìƒìœ„ 10ê°œë§Œ)
        if repo.files:
            section += "\n\n### ğŸ“„ ì£¼ìš” íŒŒì¼ ëª©ë¡"
            for file in repo.files[:10]:
                section += f"\n- `{file.path}` ({file.language}, {file.lines_of_code}ì¤„)"
            
            if len(repo.files) > 10:
                section += f"\n- ... ì™¸ {len(repo.files) - 10}ê°œ íŒŒì¼"
        
        return section
    
    def _generate_correlation_section(self, correlation: CorrelationAnalysis) -> str:
        """ì—°ê´€ë„ ë¶„ì„ ì„¹ì…˜ ìƒì„±"""
        section = f"""## ğŸ”— ë ˆí¬ì§€í† ë¦¬ ì—°ê´€ë„ ë¶„ì„

### ğŸ“Š ì—°ê´€ë„ ì ìˆ˜
- **ì „ì²´ ìœ ì‚¬ë„**: {correlation.overall_similarity:.2f}%
- **ê¸°ìˆ  ìŠ¤íƒ ìœ ì‚¬ë„**: {correlation.tech_stack_similarity:.2f}%
- **ì½”ë“œ íŒ¨í„´ ìœ ì‚¬ë„**: {correlation.code_pattern_similarity:.2f}%
- **ì•„í‚¤í…ì²˜ ìœ ì‚¬ë„**: {correlation.architecture_similarity:.2f}%"""
        
        # ê³µí†µ ì˜ì¡´ì„±
        if correlation.common_dependencies:
            section += "\n\n### ğŸ”§ ê³µí†µ ì˜ì¡´ì„±"
            for dep in correlation.common_dependencies[:15]:  # ìƒìœ„ 15ê°œë§Œ
                section += f"\n- `{dep}`"
        
        # ê³µí†µ íŒ¨í„´
        if correlation.common_patterns:
            section += "\n\n### ğŸ¨ ê³µí†µ ì½”ë“œ íŒ¨í„´"
            for pattern in correlation.common_patterns[:10]:  # ìƒìœ„ 10ê°œë§Œ
                section += f"\n- {pattern}"
        
        # ê¶Œì¥ì‚¬í•­
        if correlation.recommendations:
            section += "\n\n### ğŸ’¡ ê¶Œì¥ì‚¬í•­"
            for rec in correlation.recommendations:
                section += f"\n- {rec}"
        
        return section
    
    def _generate_summary_section(self, analysis_result: AnalysisResult) -> str:
        """ìš”ì•½ ë° ê¶Œì¥ì‚¬í•­ ì„¹ì…˜ ìƒì„±"""
        section = """## ğŸ“ ë¶„ì„ ìš”ì•½

### ğŸ¯ ì£¼ìš” ë°œê²¬ì‚¬í•­"""
        
        # ì–¸ì–´ë³„ í†µê³„
        language_stats = {}
        for repo in analysis_result.repositories:
            for file in repo.files:
                lang = file.language
                if lang not in language_stats:
                    language_stats[lang] = {"files": 0, "lines": 0}
                language_stats[lang]["files"] += 1
                language_stats[lang]["lines"] += (file.lines_of_code or 0)
        
        if language_stats:
            section += "\n\n#### ğŸ“Š ì–¸ì–´ë³„ í†µê³„"
            for lang, stats in sorted(language_stats.items(), key=lambda x: x[1]["lines"], reverse=True):
                section += f"\n- **{lang}**: {stats['files']}ê°œ íŒŒì¼, {stats['lines']:,}ì¤„"
        
        # ì½”ë“œ í’ˆì§ˆ í‰ê°€
        avg_complexity = sum(repo.code_metrics.cyclomatic_complexity for repo in analysis_result.repositories) / len(analysis_result.repositories)
        avg_maintainability = sum(repo.code_metrics.maintainability_index for repo in analysis_result.repositories) / len(analysis_result.repositories)
        
        section += f"""

#### ğŸ† ì½”ë“œ í’ˆì§ˆ í‰ê°€
- **í‰ê·  ìˆœí™˜ ë³µì¡ë„**: {avg_complexity:.2f} {'ğŸŸ¢ ì–‘í˜¸' if avg_complexity < 10 else 'ğŸŸ¡ ë³´í†µ' if avg_complexity < 20 else 'ğŸ”´ ê°œì„  í•„ìš”'}
- **í‰ê·  ìœ ì§€ë³´ìˆ˜ì„±**: {avg_maintainability:.2f} {'ğŸŸ¢ ìš°ìˆ˜' if avg_maintainability > 80 else 'ğŸŸ¡ ë³´í†µ' if avg_maintainability > 60 else 'ğŸ”´ ê°œì„  í•„ìš”'}

### ğŸš€ ê°œì„  ê¶Œì¥ì‚¬í•­
- ì½”ë“œ ë³µì¡ë„ê°€ ë†’ì€ í•¨ìˆ˜ë“¤ì˜ ë¦¬íŒ©í† ë§ ê²€í† 
- ê³µí†µ ì˜ì¡´ì„±ì„ í™œìš©í•œ ì½”ë“œ ì¬ì‚¬ìš©ì„± í–¥ìƒ
- ì¼ê´€ëœ ì½”ë”© ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì ìš©
- ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ëŒ€

---

*ì´ ë¦¬í¬íŠ¸ëŠ” CoE RAG Pipelineì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*  
*ìƒì„± ì‹œê°„: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*"""
        
        return section
    
    def save_markdown_report(self, analysis_result: AnalysisResult, filename: Optional[str] = None) -> str:
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"analysis_report_{analysis_result.analysis_id}_{timestamp}.md"
        
        filepath = os.path.join(self.output_dir, filename)
        
        try:
            md_content = self.generate_analysis_report(analysis_result)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(md_content)
            
            print(f"âœ… ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            print(f"âŒ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def generate_simple_summary(self, analysis_result: AnalysisResult) -> str:
        """ê°„ë‹¨í•œ ìš”ì•½ ë§ˆí¬ë‹¤ìš´ ìƒì„±"""
        total_files = sum(len(repo.files) for repo in analysis_result.repositories)
        total_lines = sum(repo.code_metrics.lines_of_code for repo in analysis_result.repositories)
        
        return f"""# ë¶„ì„ ìš”ì•½ - {analysis_result.analysis_id}

- **ë ˆí¬ì§€í† ë¦¬ ìˆ˜**: {len(analysis_result.repositories)}ê°œ
- **ì´ íŒŒì¼ ìˆ˜**: {total_files:,}ê°œ  
- **ì´ ì½”ë“œ ë¼ì¸**: {total_lines:,}ì¤„
- **ë¶„ì„ ìƒíƒœ**: {analysis_result.status.value}
- **ì™„ë£Œ ì‹œê°„**: {analysis_result.completed_at.strftime("%Y-%m-%d %H:%M:%S") if analysis_result.completed_at else "ì§„í–‰ì¤‘"}

ìƒì„¸ ë¶„ì„ ê²°ê³¼ëŠ” ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."""


def generate_markdown_report(analysis_result: AnalysisResult, output_dir: str = "output/markdown") -> str:
    """í¸ì˜ í•¨ìˆ˜: ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ë¡œ ìƒì„±í•˜ê³  ì €ì¥"""
    generator = MarkdownGenerator(output_dir)
    return generator.save_markdown_report(analysis_result)