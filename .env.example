# CoE-RagPipeline environment example (do NOT commit real secrets)

# LLM providers
SKAX_API_BASE=https://guest-api.sktax.chat/v1
SKAX_API_KEY=__REPLACE_ME__
SKAX_MODEL_NAME=ax4

# OpenAI settings (embeddings & chat)
OPENAI_API_KEY=__REPLACE_ME__
# Optional: custom base (Azure/OpenAI-compatible endpoint)
# OPENAI_API_BASE=https://your-endpoint/v1
# Embedding model name
OPENAI_EMBEDDING_MODEL_NAME=text-embedding-3-large
# Safety guards to avoid 413 Payload Too Large
# Per-input split guard (0 disables per-doc guard)
OPENAI_EMBED_MAX_TOKENS_PER_DOC=6000
# Aggregate token budget per embedding request (approximate)
OPENAI_EMBED_MAX_TOKENS_PER_REQUEST=120000
# Max docs per embedding batch (guards JSON size toward Chroma & provider)
OPENAI_EMBED_MAX_DOCS_PER_BATCH=64
# Hard cap for a single Chroma add() call
CHROMA_ADD_MAX_DOCS=64

# Database
DB_HOST=localhost
DB_PORT=6667
DB_USER=coe_user
DB_PASSWORD=coe_password
DB_NAME=coe_db

# Vector store
CHROMA_HOST=localhost
CHROMA_PORT=6666
CHROMA_COLLECTION_NAME=coe_documents

# Redis
REDIS_HOST=localhost
REDIS_PORT=6669
REDIS_PASSWORD=coe_redis_password
REDIS_AUTH_DB=1

# App
APP_ENV=development
DEBUG=true
LOG_LEVEL=DEBUG
RELOAD=true

# If served behind a reverse proxy under a subpath (e.g. /rag)
# set ROOT_PATH so Swagger, Redoc, and OpenAPI work correctly.
# For Nginx mapping /rag/ -> RAG service, uncomment:
# ROOT_PATH=/rag

# ITSD embedding toggles
# Whether to also store combined(title+content) texts
ITSD_EMBED_INCLUDE_COMBINED=false
# Store title-only docs (recommended: true)
ITSD_EMBED_INCLUDE_TITLE=true
# Store content-only docs (recommended: true)
ITSD_EMBED_INCLUDE_CONTENT=true

# ITSD retrieval reranking
# Enable cross-encoder rerank for top candidates (requires FlagEmbedding)
ENABLE_CROSS_ENCODER_RERANK=false
CROSS_ENCODER_MODEL=BAAI/bge-reranker-base

# ITSD dual-search fusion controls
# Choose fusion: true=RRF, false=weighted-sum
ITSD_FUSION_USE_RRF=false
ITSD_FUSION_W_TITLE=0.4
ITSD_FUSION_W_CONTENT=0.6
ITSD_FUSION_RRF_K0=60
ITSD_FUSION_TOP_K_EACH=100